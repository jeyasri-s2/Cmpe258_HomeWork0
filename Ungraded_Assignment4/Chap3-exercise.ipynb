{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chap3-exercise.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNmA9kFGjKooscMpearACgS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pktlQMHZsCxa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"au7npFoTsFBB","colab_type":"text"},"source":["Take several pictures of red, blue, and green items with your phone or other\n","digital camera.12\n","\n","– Load each image, and convert it to a tensor.\n","\n","– For each image tensor, use the .mean() method to get a sense of how bright\n","the image is.\n","\n","– Now take the mean of each channel of your images. Can you identify the red,\n","green, and blue items from only the channel averages?\n","\n","Select a relatively large file containing Python source code.\n","\n","– Build an index of all the words in the source file. (Feel free to make your\n","tokenization as simple or as complex as you like; we suggest starting by\n","replacing r\"[^a-zA-Z0-9_]+\" with spaces.)\n","\n","– Compare your index with the one you made for Pride and Prejudice. Which is\n","larger?\n","\n","– Create the one-hot encoding for the source code file.\n","\n","– What information is lost with this encoding? How does that information\n","compare with what’s lost in the Pride and Prejudice encoding?"]},{"cell_type":"code","metadata":{"id":"ywwVu4tyCDZE","colab_type":"code","colab":{}},"source":["from skimage import io, transform\n","import numpy as np\n","import torch\n","import imageio"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3kKu898VCoaw","colab_type":"code","colab":{}},"source":["images = ['blue-sky.jpg','green-tree.jpg','rose.jpg']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3aZ-fdXFqSi","colab_type":"code","colab":{}},"source":["batch_size = len(images)\n","batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n","new_h = 256\n","new_w = 256"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qnu-i81-CExA","colab_type":"code","outputId":"b5b12780-7a5a-4323-f081-5fb0d10c2176","executionInfo":{"status":"ok","timestamp":1588351856259,"user_tz":420,"elapsed":810,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}},"colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["i = 0\n","for filename in images:\n","  print(filename)\n","  img_arr = io.imread(filename)\n","  print(img_arr.shape)\n","  img = transform.resize(img_arr, (new_h, new_w))\n","  img_in = torch.from_numpy(img)\n","  out = torch.transpose(img_in, 0, 2)\n","  batch[i] = out\n","  i+=1"],"execution_count":19,"outputs":[{"output_type":"stream","text":["blue-sky.jpg\n","(669, 1000, 3)\n","green-tree.jpg\n","(194, 259, 3)\n","rose.jpg\n","(1500, 1500, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eM_Cw0cbHSx2","colab_type":"code","outputId":"a37399e9-b688-411e-dbe6-d63adda2c260","executionInfo":{"status":"ok","timestamp":1588351859338,"user_tz":420,"elapsed":329,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}},"colab":{"base_uri":"https://localhost:8080/","height":413}},"source":["batch[0]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]],\n","\n","        [[0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         ...,\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0],\n","         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"uOflB_ngG6Nr","colab_type":"text"},"source":["# Convert image to single channel"]},{"cell_type":"code","metadata":{"id":"LEMfPDVqG0xF","colab_type":"code","colab":{}},"source":["batch = batch.float()\n","batch /= 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6h6XMXaMG0oD","colab_type":"code","colab":{}},"source":["# In[7]:\n","n_channels = batch.shape[1]\n","for c in range(n_channels):\n"," mean = torch.mean(batch[:, c])\n"," std = torch.std(batch[:, c])\n"," batch[:, c] = (batch[:, c] - mean) / std"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23JczLsTHGEY","colab_type":"text"},"source":["# Print the channel values "]},{"cell_type":"code","metadata":{"id":"Y_U_ftRDG_5W","colab_type":"code","outputId":"75d2fc63-8733-40c9-c98b-48fe910bc2a9","executionInfo":{"status":"ok","timestamp":1588351941563,"user_tz":420,"elapsed":425,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Red channel\n","print(batch[:,0])\n","# blue channel\n","print(batch[:,1])\n","# green channel\n","print(batch[:,2])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["tensor([[[-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         ...,\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001]],\n","\n","        [[-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         ...,\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001],\n","         [-0.4001, -0.4001, -0.4001,  ..., -0.4001, -0.4001, -0.4001]],\n","\n","        [[ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001],\n","         [ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001],\n","         [ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001],\n","         ...,\n","         [ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001],\n","         [ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001],\n","         [ 2.4993,  2.4993,  2.4993,  ...,  2.4993, -0.4001, -0.4001]]])\n","tensor([[[-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         ...,\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999]],\n","\n","        [[-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         ...,\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999],\n","         [-0.3999, -0.3999, -0.3999,  ..., -0.3999, -0.3999, -0.3999]],\n","\n","        [[ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999],\n","         [ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999],\n","         [ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999],\n","         ...,\n","         [ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999],\n","         [ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999],\n","         [ 2.5005,  2.5005,  2.5005,  ...,  2.5005, -0.3999, -0.3999]]])\n","tensor([[[-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         ...,\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012]],\n","\n","        [[-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         ...,\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012],\n","         [-0.4012, -0.4012, -0.4012,  ..., -0.4012, -0.4012, -0.4012]],\n","\n","        [[ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012],\n","         [ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012],\n","         [ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012],\n","         ...,\n","         [ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012],\n","         [ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012],\n","         [ 2.4922,  2.4922,  2.4922,  ...,  2.4922, -0.4012, -0.4012]]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W7KF8GWbJ1C3","colab_type":"text"},"source":["# Pride and Prejudice example"]},{"cell_type":"code","metadata":{"id":"UXxa5SQSJ0y2","colab_type":"code","colab":{}},"source":["\n","with open('1342-0.txt', encoding='utf8') as f:\n","  text = f.read()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBsOpVOFKI2U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"cdf4d6b2-cfd4-4f07-f013-d15ab42beb58","executionInfo":{"status":"ok","timestamp":1588352225322,"user_tz":420,"elapsed":450,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["lines = text.split('\\n')\n","print(len(lines))\n","line = lines[100]\n","line"],"execution_count":28,"outputs":[{"output_type":"stream","text":["129\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'    train_loader = torch.utils.data.DataLoader('"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"eEo3WUu7KLma","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"31ddc8f4-634b-4a65-f142-1939b441b8a3","executionInfo":{"status":"ok","timestamp":1588352231827,"user_tz":420,"elapsed":328,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["\n","letter_tensor = torch.zeros(len(line), 128)\n","letter_tensor.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([47, 128])"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"dbnbWHOGKPr9","colab_type":"code","colab":{}},"source":["for i, letter in enumerate(line.lower().strip()):\n","  letter_index = ord(letter) if ord(letter) < 128 else 0\n","  letter_tensor[i][letter_index] = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ln_C2JOLKThQ","colab_type":"code","colab":{}},"source":["def clean_words(input_str):\n"," punctuation = \"[^a-zA-Z0-9_]+\" #'.,;:\"!?”“_-'\n"," word_list = input_str.lower().replace('\\n',' ').split()\n"," word_list = [word.strip(punctuation) for word in word_list]\n"," return word_list"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wf-MmPutKVzr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b856692d-43d2-4f60-d730-b8b07b3f08ab","executionInfo":{"status":"ok","timestamp":1588352249753,"user_tz":420,"elapsed":356,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["words_in_line = clean_words(line)\n","line, words_in_line"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('    train_loader = torch.utils.data.DataLoader(',\n"," ['train_loader', '=', 'torch.utils.data.dataloader('])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"uCQRXWnjKaWe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"73084f24-2530-4f95-efc7-b249fb54ef5d","executionInfo":{"status":"ok","timestamp":1588352304872,"user_tz":420,"elapsed":346,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["word_list = sorted(set(clean_words(text)))\n","word2index_dict = {word: i for (i, word) in enumerate(word_list)}\n","len(word2index_dict), word2index_dict['target']\n"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(262, 207)"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"aRMeDLmrLJEJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"765cf3fd-ae11-4741-b076-597e8d44516f","executionInfo":{"status":"ok","timestamp":1588352295016,"user_tz":420,"elapsed":370,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["word2index_dict"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'': 0,\n"," '\"cpu\")': 1,\n"," '\"mnist_cnn.pt\")': 2,\n"," '#': 3,\n"," '%': 4,\n"," \"'__main__':\": 5,\n"," \"'pin_memory':\": 6,\n"," '(0.3081,))': 7,\n"," '(data,': 8,\n"," '(default:': 9,\n"," \"({:.0f}%)\\\\n'.format(\": 10,\n"," '({:.0f}%)]\\\\tloss:': 11,\n"," ')),': 12,\n"," '*': 13,\n"," '**kwargs)': 14,\n"," \".7)')\": 15,\n"," '/': 16,\n"," '/=': 17,\n"," '1)': 18,\n"," \"1)')\": 19,\n"," '1):': 20,\n"," '1,': 21,\n"," \"1.0)')\": 22,\n"," '10)': 23,\n"," '100.': 24,\n"," \"1000)')\": 25,\n"," '128)': 26,\n"," \"14)')\": 27,\n"," '2)': 28,\n"," '3,': 29,\n"," '32,': 30,\n"," \"64)')\": 31,\n"," '64,': 32,\n"," ':': 33,\n"," '=': 34,\n"," '==': 35,\n"," 'batch': 36,\n"," 'batch_idx': 37,\n"," 'batch_idx,': 38,\n"," 'batch_size=args.batch_size,': 39,\n"," 'batch_size=args.test_batch_size,': 40,\n"," 'batches': 41,\n"," 'before': 42,\n"," 'ccuracy:': 43,\n"," 'class': 44,\n"," 'correct': 45,\n"," 'correct,': 46,\n"," \"ction='store_true',\": 47,\n"," 'cud': 48,\n"," 'current': 49,\n"," 'data,': 50,\n"," 'data.to(device),': 51,\n"," 'datasets,': 52,\n"," \"datasets.mnist('../data',\": 53,\n"," 'def': 54,\n"," 'default=0.7,': 55,\n"," 'default=1,': 56,\n"," 'default=1.0,': 57,\n"," 'default=10,': 58,\n"," 'default=1000,': 59,\n"," 'default=14,': 60,\n"," 'default=64,': 61,\n"," 'default=false,': 62,\n"," 'device': 63,\n"," 'device,': 64,\n"," 'dim=1)': 65,\n"," 'download=true,': 66,\n"," 'else': 67,\n"," 'enumerate(train_loader):': 68,\n"," 'epoch': 69,\n"," 'epoch)': 70,\n"," 'epoch):': 71,\n"," 'epoch,': 72,\n"," 'epoch:': 73,\n"," 'epochs': 74,\n"," \"example')\": 75,\n"," 'f': 76,\n"," 'f.log_softmax(x,': 77,\n"," 'f.max_pool2d(x,': 78,\n"," 'f.nll_loss(output,': 79,\n"," 'f.relu(x)': 80,\n"," 'for': 81,\n"," 'forward(self,': 82,\n"," 'from': 83,\n"," 'future': 84,\n"," 'gamm': 85,\n"," 'gamma=args.gamma)': 86,\n"," 'get': 87,\n"," \"help='disables\": 88,\n"," \"help='for\": 89,\n"," \"help='how\": 90,\n"," \"help='input\": 91,\n"," \"help='learning\": 92,\n"," \"help='number\": 93,\n"," \"help='random\": 94,\n"," 'if': 95,\n"," 'import': 96,\n"," 'in': 97,\n"," 'index': 98,\n"," 'init__(self):': 99,\n"," 'keepdim=true)': 100,\n"," 'kwargs': 101,\n"," 'len(data),': 102,\n"," 'len(test_loader.dataset)': 103,\n"," 'len(test_loader.dataset)))': 104,\n"," 'len(test_loader.dataset),': 105,\n"," 'len(train_loader),': 106,\n"," 'len(train_loader.dataset),': 107,\n"," 'log-probability': 108,\n"," 'logging': 109,\n"," 'loss': 110,\n"," 'loss.backward()': 111,\n"," 'loss.item()))': 112,\n"," 'loss:': 113,\n"," 'lr=args.lr)': 114,\n"," 'main()': 115,\n"," 'main():': 116,\n"," 'many': 117,\n"," 'max': 118,\n"," \"metavar='lr',\": 119,\n"," \"metavar='m',\": 120,\n"," \"metavar='n',\": 121,\n"," \"metavar='s',\": 122,\n"," 'mnist': 123,\n"," 'model': 124,\n"," \"model')\": 125,\n"," 'model(data)': 126,\n"," 'model,': 127,\n"," 'model.eval()': 128,\n"," 'model.train()': 129,\n"," 'name': 130,\n"," 'nd': 131,\n"," 'net().to(device)': 132,\n"," 'net(nn.module):': 133,\n"," 'nn': 134,\n"," 'nn.conv2d(1,': 135,\n"," 'nn.conv2d(32,': 136,\n"," 'nn.dropout2d(0.25)': 137,\n"," 'nn.dropout2d(0.5)': 138,\n"," 'nn.linear(128,': 139,\n"," 'nn.linear(9216,': 140,\n"," 'not': 141,\n"," 'of': 142,\n"," 'optim': 143,\n"," 'optim.adadelta(model.parameters(),': 144,\n"," 'optimizer': 145,\n"," 'optimizer,': 146,\n"," 'optimizer.step()': 147,\n"," 'optimizer.zero_grad()': 148,\n"," 'output': 149,\n"," 'output.argmax(dim=1,': 150,\n"," 'parser': 151,\n"," \"parser.add_argument('--batch-size',\": 152,\n"," \"parser.add_argument('--epochs',\": 153,\n"," \"parser.add_argument('--gamma',\": 154,\n"," \"parser.add_argument('--log-interval',\": 155,\n"," \"parser.add_argument('--lr',\": 156,\n"," \"parser.add_argument('--no-cuda',\": 157,\n"," \"parser.add_argument('--save-model',\": 158,\n"," \"parser.add_argument('--seed',\": 159,\n"," \"parser.add_argument('--test-batch-size',\": 160,\n"," 'parser.parse_args()': 161,\n"," 'pred': 162,\n"," 'pred.eq(target.view_as(pred)).sum().item()': 163,\n"," \"print('\\\\ntest\": 164,\n"," \"print('train\": 165,\n"," 'print_function': 166,\n"," 'range(1,': 167,\n"," 'rate': 168,\n"," \"reduction='sum').item()\": 169,\n"," 'return': 170,\n"," 'rgparse': 171,\n"," \"rgparse.argumentparser(description='pytorch\": 172,\n"," 'rgs': 173,\n"," 'rgs.epochs': 174,\n"," 'rgs.log_interval': 175,\n"," 'rgs.no_cud': 176,\n"," 'rgs.save_model:': 177,\n"," 's': 178,\n"," 'saving': 179,\n"," 'scheduler': 180,\n"," 'scheduler.step()': 181,\n"," 'seed': 182,\n"," 'self).__init__()': 183,\n"," 'self.conv1': 184,\n"," 'self.conv1(x)': 185,\n"," 'self.conv2': 186,\n"," 'self.conv2(x)': 187,\n"," 'self.dropout1': 188,\n"," 'self.dropout1(x)': 189,\n"," 'self.dropout2': 190,\n"," 'self.dropout2(x)': 191,\n"," 'self.fc1': 192,\n"," 'self.fc1(x)': 193,\n"," 'self.fc2': 194,\n"," 'self.fc2(x)': 195,\n"," 'set:': 196,\n"," 'settings': 197,\n"," 'shuffle=true,': 198,\n"," 'size': 199,\n"," \"status')\": 200,\n"," 'step': 201,\n"," 'step_size=1,': 202,\n"," 'steplr': 203,\n"," 'steplr(optimizer,': 204,\n"," 'sum': 205,\n"," 'super(net,': 206,\n"," 'target': 207,\n"," 'target)': 208,\n"," 'target,': 209,\n"," 'target.to(device)': 210,\n"," 'test(model,': 211,\n"," 'test_loader': 212,\n"," 'test_loader)': 213,\n"," 'test_loader):': 214,\n"," 'test_loader:': 215,\n"," 'test_loss': 216,\n"," 'test_loss,': 217,\n"," 'testing': 218,\n"," 'the': 219,\n"," 'to': 220,\n"," 'torch': 221,\n"," 'torch.cuda.is_available()': 222,\n"," 'torch.device(\"cuda\"': 223,\n"," 'torch.flatten(x,': 224,\n"," 'torch.manual_seed(args.seed)': 225,\n"," 'torch.nn': 226,\n"," 'torch.nn.functional': 227,\n"," 'torch.no_grad():': 228,\n"," 'torch.optim': 229,\n"," 'torch.optim.lr_scheduler': 230,\n"," 'torch.save(model.state_dict(),': 231,\n"," 'torch.utils.data.dataloader(': 232,\n"," 'torchvision': 233,\n"," 'train': 234,\n"," 'train(args,': 235,\n"," 'train=false,': 236,\n"," 'train=true,': 237,\n"," 'train_loader': 238,\n"," 'train_loader,': 239,\n"," 'training': 240,\n"," \"training')\": 241,\n"," 'transform=transforms.compose(': 242,\n"," 'transforms': 243,\n"," 'transforms.normalize((0.1307,),': 244,\n"," 'transforms.totensor(),': 245,\n"," 'true}': 246,\n"," 'type=float,': 247,\n"," 'type=int,': 248,\n"," 'up': 249,\n"," 'use_cud': 250,\n"," 'verage': 251,\n"," 'wait': 252,\n"," 'with': 253,\n"," 'x': 254,\n"," 'x):': 255,\n"," \"{'num_workers':\": 256,\n"," '{:.4f},': 257,\n"," \"{:.6f}'.format(\": 258,\n"," '{}': 259,\n"," '{}/{}': 260,\n"," '\\ufefffrom': 261}"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"SoUGF229KcVe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"ac75edb7-1202-47b8-bfcb-af662d2486c2","executionInfo":{"status":"ok","timestamp":1588352317372,"user_tz":420,"elapsed":347,"user":{"displayName":"Jeyasri Subramanian","photoUrl":"","userId":"02962323640404076009"}}},"source":["word_tensor = torch.zeros(len(words_in_line), len(word2index_dict))\n","for i, word in enumerate(words_in_line):\n","  word_index = word2index_dict[word]\n","  word_tensor[i][word_index] = 1\n","  print('{:2} {:4} {}'.format(i, word_index, word))\n","print(word_tensor.shape)"],"execution_count":38,"outputs":[{"output_type":"stream","text":[" 0  238 train_loader\n"," 1   34 =\n"," 2  232 torch.utils.data.dataloader(\n","torch.Size([3, 262])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lgFz0598KcNQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
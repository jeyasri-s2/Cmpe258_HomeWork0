{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-GradedAsgmt-AutodiffKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRk56pJncugB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZC0UNC9cveJ",
        "colab_type": "text"
      },
      "source": [
        "Autodiff MNIST Dataset\n",
        "\n",
        "https://github.com/gtoubassi/simple-autodiff/blob/master/mnist.py\n",
        "\n",
        "https://github.com/HIPS/autograd/blob/master/examples/neural_net.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkWFJU1Vc3ij",
        "colab_type": "text"
      },
      "source": [
        "# do keras models for four problems (4 different data sets)\n",
        " \n",
        "a) boolean cross entropy -\n",
        " https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/ \n",
        "\n",
        "b) sparse categorical crossentropy (softmax) - try to get images of 7 classes with images.google.com google search and classify \n",
        "\n",
        "https://www.dlology.com/blog/how-to-use-keras-sparse_categorical_crossentropy/ \n",
        "\n",
        "c) logistic regression https://medium.com/@luwei.io/logistic-regression-with-keras-d75d640d175e\n",
        "\n",
        "d) multi head classification (multi class classification) https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzDUzla_T6Ef",
        "colab_type": "code",
        "outputId": "1e3d0fb2-9d36-4eef-c364-8380a458b0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr 26 16:26:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUNdHcHZU3tt",
        "colab_type": "code",
        "outputId": "6e081727-2a6c-4568-d970-6dc2d69955f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HYDByXjvQXJ",
        "colab_type": "text"
      },
      "source": [
        "#Autodiff from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oUGVVJCVGId",
        "colab_type": "code",
        "outputId": "a52fea6b-9e6d-45ac-ec1b-29ce51af332e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\"\"\"A multi-layer perceptron for classification of MNIST handwritten digits.\"\"\"\n",
        "from __future__ import absolute_import, division\n",
        "from __future__ import print_function\n",
        "import autograd.numpy as np\n",
        "import autograd.numpy.random as npr\n",
        "from autograd.scipy.special import logsumexp\n",
        "from autograd import grad\n",
        "from autograd.misc.flatten import flatten\n",
        "from autograd.misc.optimizers import adam\n",
        "#from data import load_mnist\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def init_random_params(scale, layer_sizes, rs=npr.RandomState(0)):\n",
        "    \"\"\"Build a list of (weights, biases) tuples,\n",
        "       one for each layer in the net.\"\"\"\n",
        "    return [(scale * rs.randn(m, n),   # weight matrix\n",
        "             scale * rs.randn(n))      # bias vector\n",
        "            for m, n in zip(layer_sizes[:-1], layer_sizes[1:])]\n",
        "\n",
        "def neural_net_predict(params, inputs):\n",
        "    \"\"\"Implements a deep neural network for classification.\n",
        "       params is a list of (weights, bias) tuples.\n",
        "       inputs is an (N x D) matrix.\n",
        "       returns normalized class log-probabilities.\"\"\"\n",
        "    for W, b in params:\n",
        "        outputs = np.dot(inputs, W) + b\n",
        "        inputs = np.tanh(outputs)\n",
        "    return outputs - logsumexp(outputs, axis=1, keepdims=True)\n",
        "\n",
        "def l2_norm(params):\n",
        "    \"\"\"Computes l2 norm of params by flattening them into a vector.\"\"\"\n",
        "    flattened, _ = flatten(params)\n",
        "    return np.dot(flattened, flattened)\n",
        "\n",
        "def log_posterior(params, inputs, targets, L2_reg):\n",
        "    log_prior = -L2_reg * l2_norm(params)\n",
        "    log_lik = np.sum(neural_net_predict(params, inputs) * targets)\n",
        "    return log_prior + log_lik\n",
        "\n",
        "def accuracy(params, inputs, targets):\n",
        "    target_class    = np.argmax(targets, axis=1)\n",
        "    predicted_class = np.argmax(neural_net_predict(params, inputs), axis=1)\n",
        "    return np.mean(predicted_class == target_class)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Model parameters\n",
        "    layer_sizes = [784, 200, 100, 10]\n",
        "    L2_reg = 1.0\n",
        "\n",
        "    # Training parameters\n",
        "    param_scale = 0.1\n",
        "    batch_size = 256\n",
        "    num_epochs = 5\n",
        "    step_size = 0.001\n",
        "\n",
        "    print(\"Loading training data...\")\n",
        "    #N, train_images, train_labels, test_images,  test_labels = load_mnist()\n",
        "    partial_flatten = lambda x : np.reshape(x, (x.shape[0], np.prod(x.shape[1:])))\n",
        "    one_hot = lambda x, k: np.array(x[:,None] == np.arange(k)[None, :], dtype=int)\n",
        "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "    N = train_images.shape[0]  \n",
        "    train_images = partial_flatten(train_images) / 255.0\n",
        "    test_images  = partial_flatten(test_images)  / 255.0\n",
        "    train_labels = one_hot(train_labels, 10)\n",
        "    test_labels = one_hot(test_labels, 10)\n",
        "    init_params = init_random_params(param_scale, layer_sizes)\n",
        "\n",
        "    num_batches = int(np.ceil(len(train_images) / batch_size))\n",
        "    def batch_indices(iter):#\n",
        "        idx = iter % num_batches\n",
        "        return slice(idx * batch_size, (idx+1) * batch_size)\n",
        "\n",
        "    # Define training objective\n",
        "    def objective(params, iter):\n",
        "        idx = batch_indices(iter)\n",
        "        return -log_posterior(params, train_images[idx], train_labels[idx], L2_reg)\n",
        "\n",
        "    # Get gradient of objective using autograd.\n",
        "    objective_grad = grad(objective)\n",
        "\n",
        "    print(\"     Epoch     |    Train accuracy  |       Test accuracy  \")\n",
        "    def print_perf(params, iter, gradient):\n",
        "        if iter % num_batches == 0:\n",
        "            train_acc = accuracy(params, train_images, train_labels)\n",
        "            test_acc  = accuracy(params, test_images, test_labels)\n",
        "            print(\"{:15}|{:20}|{:20}\".format(iter//num_batches, train_acc, test_acc))\n",
        "\n",
        "    # The optimizers provided can optimize lists, tuples, or dicts of parameters.\n",
        "    optimized_params = adam(objective_grad, init_params, step_size=step_size,\n",
        "                            num_iters=num_epochs * num_batches, callback=print_perf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "     Epoch     |    Train accuracy  |       Test accuracy  \n",
            "              0| 0.06888333333333334|              0.0657\n",
            "              1|             0.90525|              0.9105\n",
            "              2|  0.9107833333333333|              0.9136\n",
            "              3|  0.9164833333333333|               0.919\n",
            "              4|  0.9217333333333333|              0.9248\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}